
@Proceedings{CD2019,
  title =     {Proceedings of Machine Learning Research},
  booktitle = {Proceedings of Machine Learning Research},
  editor =    {Thuc Duy Le and Jiuyong Li and Kun Zhang and Emre K{\i}c{\i}man Peng Cui and Aapo Hyv\"{a}rinen},
  publisher = {PMLR},
  name = {The 2019 ACM SIGKDD Workshop on Causal Discovery},
  shortname = {CD 2019},
  series =    {Proceedings of Machine Learning Research},
  volume =    104,
  start = {2019-08-05},
  end = {2019-08-05},
  url = {http://nugget.unisa.edu.au/CD2019/cfp.html},
  address = {Anchorage, Alaska, USA},
  published = {2019-07-26}
}


@InProceedings{le19,
  title = 	 {Preface: The 2019 ACM SIGKDD Workshop on Causal Discovery },
  author = 	 {Le, Thuc Duy and Li, Jiuyong and Zhang, Kun and K{\i}c{\i}man, Emre and Cui, Peng and  Hyv\"{a}rinen, Aapo},
  booktitle = 	 {Proceedings of the 2019 KDD Workshop on Causal Discovery},
  pages = 	 {1--3},
  year = 	 {2019},
  editor =    {Thuc Duy Le, Jiuyong Li, Kun Zhang, Emre K{\i}c{\i}man, Peng Cui, and Aapo Hyv\"{a}rinen},
  volume =  {104},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v104/le19/le19.pdf},
  url = 	 {http://proceedings.mlr.press/v104/le19.html},
  abstract = 	 {Preface to the 2019 KDD Workshop on Causal Discovery (CD19)}
}


@InProceedings{andrews19,
  title = 	 {Learning High-dimensional Directed Acyclic Graphs with Mixed Data-types},
  author = 	 {Andrews, Bryan and Ramsey, Joseph and Cooper, Gregory F.},
  booktitle = 	 {Proceedings of the 2019 KDD Workshop on Causal Discovery},
  pages = 	 {4--21},
   year = 	 {2019},
  editor =    {Thuc Duy Le, Jiuyong Li, Kun Zhang, Emre K{\i}c{\i}man, Peng Cui, and Aapo Hyv\"{a}rinen},
  volume = 	{104},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v104/andrews19/andrews19.pdf},
  url = 	 {http://proceedings.mlr.press/v104/andrews19.html},
  abstract = 	 {In recent years, great strides have been made for causal structure learning in the high- dimensional setting and in the mixed data-type setting when there are both discrete and continuous variables. However, due to the complications involved with modeling continuous-discrete variable interactions, the intersection of these two settings has been relatively understudied. The current paper explores the problem of efficiently extending causal structure learning algorithms to high-dimensional data with mixed data-types. First, we characterize a model over continuous and discrete variables. Second, we derive a de- generate Gaussian (DG) score for mixed data-types and discuss its asymptotic properties. Lastly, we demonstrate the practicality of the DG score on learning causal structures from simulated data sets.}
}


@InProceedings{assaad19,
	title = 	 {Scaling Causal Inference in Additive Noise Models},
	author = 	 {Assaad, Charles Karim and Devijver, Emilie and Gaussier, Eric and Ait-Bachir, Ali},
	booktitle = 	 {Proceedings of the 2019 KDD Workshop on Causal Discovery},
 	pages = 	 {22--33},
   	year = 	 {2019},
  	editor =    {Thuc Duy Le, Jiuyong Li, Kun Zhang, Emre K{\i}c{\i}man, Peng Cui, and Aapo Hyv\"{a}rinen},
 	 volume = 	{104},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v104/assaad19/assaad19.pdf},
  url = 	 {http://proceedings.mlr.press/v104/assaad19.html},	
  abstract = 	 {The discovery of causal relationships from observations is a fundamental and difficult problem. We address it in the context of Additive Noise Models, and show, through both consistency analysis and experiments, that the state-of-art causal inference procedure on such models can be made simpler and faster, without loss of performance. Indeed, the method we propose uses one regressor instead of two in the bivariate case and 2(d − 1) regressors instead of (d^2 − 1) in the multivariate case with d random variables. In addition, we show how one can, from the regressors we use, accelerate the computation of the Hilbert-Schmidt Independence Criterion, a standard independence measure used in several causal inference procedures.}
}


@InProceedings{du19,
  title = 	 {Improve User Retention with Causal Learning},
  author = 	 {Du, Shuyang and Lee, James and Ghaffarizadeh, Farzin},
  booktitle = 	 {Proceedings of the 2019 KDD Workshop on Causal Discovery},
  pages = 	 {34--49},
   year = 	 {2019},
  editor =    {Thuc Duy Le, Jiuyong Li, Kun Zhang, Emre K{\i}c{\i}man, Peng Cui, and Aapo Hyv\"{a}rinen},
  volume = 	{104},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v104/du19/du19.pdf},
  url = 	 {http://proceedings.mlr.press/v104/du19.html},
  abstract = 	 {User retention is a key focus for consumer based internet companies and promotions are an effective lever to improve retention. However, companies rely either on non-causal churn prediction to capture heterogeneity or on regular A/B testing to capture average treatment effect. In this paper, we propose a heterogeneous treatment effect optimization framework to capture both heterogeneity and causal effect.
We propose two algorithms to maximize heterogeneous treatment effect: 1) Ranking based on point estimates of heterogeneous treatment effects obtained using existing esti- mation methods with training labels adjusted based on Lagrangian Subgradient method. 2) A novel ranking algorithm which combines estimation and optimization in one stage and directly optimizes for the aggregated targeted treatment effect.
We also develop an evaluation metric that captures the real-world business value of different methods and use this to evaluate various approaches on our large-scale experiment data set both offline and online. Our algorithm (approach 2) performs significantly better than random explore benchmark and existing estimators (approach 1) in both offline and online tests. This method has been deployed to production and is currently live in multiple cities all over the world.}
}

@InProceedings{lin19,
  title = 	 {Universal Causal Evaluation Engine: An API for empirically evaluating causal inference models},
  author = 	 {Lin, Alexander and Merchant, Amil and Sarkar, Suproteem K. and D'Amour, Alexander},
  booktitle = 	 {Proceedings of the 2019 KDD Workshop on Causal Discovery},
  pages = 	 {50--58},
   year = 	 {2019},
  editor =    {Thuc Duy Le, Jiuyong Li, Kun Zhang, Emre K{\i}c{\i}man, Peng Cui, and Aapo Hyv\"{a}rinen},
  volume = 	{104},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v104/lin19/lin19.pdf},
  url = 	 {http://proceedings.mlr.press/v104/lin19.html},
  abstract = 	 {A major driver in the success of predictive machine learning has been the “common task framework,” where community-wide benchmarks are shared for evaluating new algorithms. This pattern, however, is difficult to implement for causal learning tasks because the ground truth in these tasks is in general unobservable. Instead, causal inference methods are often evaluated on synthetic or semi-synthetic datasets that incorporate idiosyncratic assump- tions about the underlying data-generating process. These evaluations are often proposed in conjunction with new causal inference methods—as a result, many methods are eval- uated on incomparable benchmarks. To address this issue, we establish an API for gen- eralized causal inference model assessment, with the goal of developing a platform that lets researchers deploy and evaluate new model classes in instances where treatments are explicitly known. The API uses a common interface for each of its components, and it allows for new methods and datasets to be evaluated and saved for future benchmarking.}
}

@InProceedings{schmidt19,
  title = 	 {Load-Balanced Parallel Constraint-Based Causal Structure Learning on Multi-Core Systems for High-Dimensional Data},
  author = 	 {Schmidt, Christopher and  Huegle, Johannes and Bode, Philipp and Uflacker, Matthias},
  booktitle = 	 {Proceedings of the 2019 KDD Workshop on Causal Discovery},
  pages = 	 {59--77},
   year = 	 {2019},
  editor =    {Thuc Duy Le, Jiuyong Li, Kun Zhang, Emre K{\i}c{\i}man, Peng Cui, and Aapo Hyv\"{a}rinen},
  volume = 	{104},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v104/schmidt19/schmidt19.pdf},
  url = 	 {http://proceedings.mlr.press/v104/schmidt19.html},
  abstract = 	 {In the context of high-dimensional data state-of-the-art methods for constraint-based causal structure learning, such as the PC algorithm, are limited in their application through their worst case exponential computational complexity. To address the resulting long execution time, several parallel extensions have been developed to exploit modern multi-core systems. These extensions apply a static distribution of tasks to the execution units to achieve paral- lelism, which introduces the problem of load imbalance. In our work, we propose a parallel implementation that follows a dynamic task distribution in order to avoid situations of load imbalance and improve the execution time. On the basis of an experimental evaluation on real-world high dimensional datasets, we show that our implementation has a better load balancing compared to an existing parallel implementation in the context of multivariate normal distributed data. For datasets that introduce load imbalance, our dynamic task distribution approach outperforms existing static approaches by factors up to 2.4. Overall, we increase the speed up from factors of up to 27, for the static approach, to factors of up to 39 for the dynamic approach, when scaling to 80 cores compared to a non-parallel execution.}
}

@InProceedings{soni19,
  title = 	 {Detecting Social Influence in Event Cascades by Comparing Discriminative Rankers},
  author = 	 {Soni, Sandeep and Ramirez, Shawn Ling and Eisenstein, Jacob Joseph},
  booktitle = 	 {Proceedings of the 2019 KDD Workshop on Causal Discovery},
  pages = 	 {78--99},
   year = 	 {2019},
  editor =    {Thuc Duy Le, Jiuyong Li, Kun Zhang, Emre K{\i}c{\i}man, Peng Cui, and Aapo Hyv\"{a}rinen},
  volume = 	{104},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v104/soni19/soni19.pdf},
  url = 	 {http://proceedings.mlr.press/v104/soni19.html},
  abstract = 	 {The global dynamics of event cascades are often governed by the local dynamics of peer influence. However, detecting social influence from observational data is challenging due to confounds like homophily and practical issues like missing data. We propose a simple discriminative method to detect influence from observational data. The core of the approach is to train a ranking algorithm to predict the source of the next event in a cascade, and compare its out-of-sample accuracy against a competitive baseline which lacks access to features corresponding to social influence. We analyze synthetically generated data to show that this method correctly identifies influence in the presence of confounds, and is robust to both missing data and misspecification — unlike well-known alternatives. We apply the method to two real-world datasets: (1) the co-sponsorship of legislation in the U.S. House of Representatives on a social network of shared campaign donors; (2) rumors about the Higgs boson discovery on a follower network of 105 Twitter accounts. Our model identifies the role of social influence in these scenarios and uses it to make more accurate predictions about the future trajectory of cascades.}
}

@InProceedings{strobl19,
  title = 	 {Improved Causal Discovery from Longitudinal Data Using a Mixture of DAGs},
  author = 	 {Strobl, Eric V.},
  booktitle = 	 {Proceedings of the 2019 KDD Workshop on Causal Discovery},
  pages = 	 {100--133},
   year = 	 {2019},
  editor =    {Thuc Duy Le, Jiuyong Li, Kun Zhang, Emre K{\i}c{\i}man, Peng Cui, and Aapo Hyv\"{a}rinen},
  volume = 	{104},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v104/strobl19/strobl19.pdf},
  url = 	 {http://proceedings.mlr.press/v104/strobl19.html},
  abstract = 	 {Many causal processes in biomedicine contain cycles and evolve. However, most causal discovery algorithms assume that the underlying causal process follows a single directed acyclic graph (DAG) that does not change over time. The algorithms can therefore infer erroneous causal relations with high confidence when run on real biomedical data. In this paper, I relax the single DAG assumption by modeling causal processes using a mixture of DAGs so that the graph can change over time. I then describe a causal discovery algorithm called Causal Inference over Mixtures (CIM) to infer causal structure from a mixture of DAGs using longitudinal data. CIM improves the accuracy of causal discovery on both real and synthetic clinical datasets even when cycles, non-stationarity, non-linearity, latent variables and selection bias exist simultaneously. Code is available at https://github.com/ericstrobl/CIM.}
}

















